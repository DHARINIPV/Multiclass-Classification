# -*- coding: utf-8 -*-
"""Multiclass Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XRCuYOxIc6e0AgaWHZAIx1RrxzTSmWJ6
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!kaggle datasets download wanyuh/dogcatpanda

import zipfile
zip_ref = zipfile.ZipFile('/content/dogcatpanda.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

import os

base_path = "/content"
for root, dirs, files in os.walk(base_path):
    print("üìÇ", root)
    for d in dirs:
        print("   üìÅ", d)
    for f in files[:5]:  # just show first 5 files in each folder
        print("   üìÑ", f)
    print()

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt

train_dir = "/content/dogcatpanda/training_set"
test_dir = "/content/dogcatpanda/test_set"

img_height, img_width = 128, 128
batch_size = 32

datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_data = datagen.flow_from_directory(
    train_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

val_data = datagen.flow_from_directory(
    train_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation',
    shuffle=True
)

test_datagen = ImageDataGenerator(rescale=1./255)
test_data = test_datagen.flow_from_directory(
    test_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)

from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping

# Early stopping callback
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

model = models.Sequential([
    layers.InputLayer(input_shape=(128, 128, 3)),

    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),

    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),

    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.4),
    layers.Dense(train_data.num_classes, activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=30,
    callbacks=[early_stop]
)

# Accuracy
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

loss, acc = model.evaluate(test_data)
print(f"‚úÖ Test Accuracy: {acc:.2f}")

import numpy as np

# Get model predictions on test data
pred_probs = model.predict(test_data)

# Convert probabilities to predicted class index
pred_classes = np.argmax(pred_probs, axis=1)

# True labels
true_classes = test_data.classes

# Class label names
class_labels = list(test_data.class_indices.keys())

for i in range(10):
    print(f"Image {i+1}:")
    print("  ‚úÖ True:", class_labels[true_classes[i]])
    print("  ü§ñ Pred:", class_labels[pred_classes[i]])
    print("  üîÆ Conf:", pred_probs[i])
    print()

from tensorflow.keras.preprocessing import image
import numpy as np

img_path = 'image2.jpeg'

img = image.load_img(img_path, target_size=(128, 128))

# Convert to array
img_array = image.img_to_array(img)
img_array = img_array / 255.0  # normalize like training set
img_array = np.expand_dims(img_array, axis=0)  # add batch dimension

pred = model.predict(img_array)
predicted_class = np.argmax(pred)
confidence = np.max(pred)

class_labels = list(train_data.class_indices.keys())

plt.imshow(img)
print(f"Predicted Class: {class_labels[predicted_class]}")
print(f"Confidence: {confidence:.2f}")

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

test_data = test_datagen.flow_from_directory(
    test_dir,
    target_size=(128,128),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

# Predict probabilities
pred_probs = model.predict(test_data)

# Convert to predicted class indices
y_pred = np.argmax(pred_probs, axis=1)

#True class indices
y_true = test_data.classes

# Class labels
class_names = list(test_data.class_indices.keys())

# Compute confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Display it
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
disp.plot(cmap='Blues', xticks_rotation=45)
plt.title("Confusion Matrix")
plt.show()

